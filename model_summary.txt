Print Model:
---------------------------------------------
Gamma(
  (encoder): ConvolutionalVisionTransformer(
    (stage0): VisionTransformer(
      (patch_embed): ConvEmbed(
        (proj): Conv2d(5, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))
        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=64, out_features=64, bias=True)
            (proj_k): Linear(in_features=64, out_features=64, bias=True)
            (proj_v): Linear(in_features=64, out_features=64, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=64, out_features=64, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=64, out_features=256, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=256, out_features=64, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (stage1): VisionTransformer(
      (patch_embed): ConvEmbed(
        (proj): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=192, out_features=192, bias=True)
            (proj_k): Linear(in_features=192, out_features=192, bias=True)
            (proj_v): Linear(in_features=192, out_features=192, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=192, out_features=192, bias=True)
            (proj_k): Linear(in_features=192, out_features=192, bias=True)
            (proj_v): Linear(in_features=192, out_features=192, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
              (bn): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=192, out_features=192, bias=True)
            (proj_k): Linear(in_features=192, out_features=192, bias=True)
            (proj_v): Linear(in_features=192, out_features=192, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (stage2): VisionTransformer(
      (patch_embed): ConvEmbed(
        (proj): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
      (pos_drop): Dropout(p=0.0, inplace=False)
      (blocks): ModuleList(
        (0): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.008)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.015)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.023)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.031)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.038)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (6): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.046)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (7): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.054)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (8): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.062)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (9): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.069)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (10): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.077)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (11): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.085)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (12): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.092)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (13): Block(
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): Attention(
            (conv_proj_q): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_k): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (conv_proj_v): Sequential(
              (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
              (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
              (rearrage): Rearrange('b c h w -> b (h w) c')
            )
            (proj_q): Linear(in_features=384, out_features=384, bias=True)
            (proj_k): Linear(in_features=384, out_features=384, bias=True)
            (proj_v): Linear(in_features=384, out_features=384, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
          )
          (drop_path): DropPath(drop_prob=0.100)
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): QuickGELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
    (expander): Conv2d(384, 1024, kernel_size=[2, 2], stride=[2, 2], padding=[1, 1])
    (expander_norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (expander_act): LeakyReLU(negative_slope=0.01)
  )
  (decoder): DecoderCVT(
    (contractor): Conv2d(1024, 384, kernel_size=[2, 2], stride=[1, 1], padding=[1, 1])
    (bn_contractor): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (leaky_relu): LeakyReLU(negative_slope=0.01)
    (up2): UpSampleBN(
      (_net): Sequential(
        (0): Conv2d(768, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.01)
        (3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): LeakyReLU(negative_slope=0.01)
        (6): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): LeakyReLU(negative_slope=0.01)
      )
    )
    (up1): UpSampleBN(
      (_net): Sequential(
        (0): Conv2d(384, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.01)
        (3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): LeakyReLU(negative_slope=0.01)
        (6): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): LeakyReLU(negative_slope=0.01)
      )
    )
    (up0): UpSampleBN(
      (_net): Sequential(
        (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): LeakyReLU(negative_slope=0.01)
        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (5): LeakyReLU(negative_slope=0.01)
        (6): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (8): LeakyReLU(negative_slope=0.01)
      )
    )
    (up_x): Upsample(scale_factor=2.0, mode=bilinear)
    (conv): Conv2d(64, 108, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (relu): ReLU(inplace=True)
  )
  (adaptive_bins_layer): mViT(
    (patch_transformer): PatchTransformerEncoder(
      (transformer_encoder): TransformerEncoder(
        (layers): ModuleList(
          (0): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (1): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (2): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
          (3): TransformerEncoderLayer(
            (self_attn): MultiheadAttention(
              (out_proj): _LinearWithBias(in_features=128, out_features=128, bias=True)
            )
            (linear1): Linear(in_features=128, out_features=1024, bias=True)
            (dropout): Dropout(p=0.1, inplace=False)
            (linear2): Linear(in_features=1024, out_features=128, bias=True)
            (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            (dropout1): Dropout(p=0.1, inplace=False)
            (dropout2): Dropout(p=0.1, inplace=False)
          )
        )
      )
      (embedding_convPxP): Conv2d(5, 128, kernel_size=(16, 16), stride=(16, 16))
    )
    (conv3x3): Conv2d(5, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (regressor): Sequential(
      (0): Linear(in_features=128, out_features=256, bias=True)
      (1): LeakyReLU(negative_slope=0.01)
      (2): Linear(in_features=256, out_features=256, bias=True)
      (3): LeakyReLU(negative_slope=0.01)
      (4): Linear(in_features=256, out_features=3, bias=True)
    )
  )
)

Print Train TD Model:
------------------------------------
multilayer()

Print Val TD Model:
---------------------------------------
multilayer()
------------------------------------------------------------------------------------

Model Summary:
--------------------------------------===============================================================================================
Layer (type:depth-idx)                        Output Shape              Param #
===============================================================================================
├─ConvolutionalVisionTransformer: 1-1         [-1, 1024, 17, 13]        --
|    └─VisionTransformer: 2-1                 [-1, 64, 128, 96]         --
|    |    └─ConvEmbed: 3-1                    [-1, 64, 128, 96]         15,872
|    |    └─Dropout: 3-2                      [-1, 12288, 64]           --
|    └─VisionTransformer: 2-2                 [-1, 192, 64, 48]         --
|    |    └─ConvEmbed: 3-3                    [-1, 192, 64, 48]         111,168
|    |    └─Dropout: 3-4                      [-1, 3072, 192]           --
|    └─VisionTransformer: 2-3                 [-1, 384, 32, 24]         --
|    |    └─ConvEmbed: 3-5                    [-1, 384, 32, 24]         664,704
|    |    └─Dropout: 3-6                      [-1, 768, 384]            --
|    └─Conv2d: 2-4                            [-1, 1024, 17, 13]        1,573,888
|    └─BatchNorm2d: 2-5                       [-1, 1024, 17, 13]        2,048
|    └─LeakyReLU: 2-6                         [-1, 1024, 17, 13]        --
├─DecoderCVT: 1-2                             [-1, 108, 256, 192]       --
|    └─Conv2d: 2-7                            [-1, 384, 18, 14]         1,573,248
|    └─BatchNorm2d: 2-8                       [-1, 384, 18, 14]         768
|    └─LeakyReLU: 2-9                         [-1, 384, 18, 14]         --
|    └─UpSampleBN: 2-10                       [-1, 192, 32, 24]         --
|    |    └─Sequential: 3-7                   [-1, 192, 32, 24]         4,647,744
|    └─UpSampleBN: 2-11                       [-1, 64, 64, 48]          --
|    |    └─Sequential: 3-8                   [-1, 64, 64, 48]          1,107,264
|    └─UpSampleBN: 2-12                       [-1, 64, 128, 96]         --
|    |    └─Sequential: 3-9                   [-1, 64, 128, 96]         148,032
|    └─Upsample: 2-13                         [-1, 64, 256, 192]        --
|    └─Conv2d: 2-14                           [-1, 108, 256, 192]       172,908
|    └─ReLU: 2-15                             [-1, 108, 256, 192]       --
├─mViT: 1-3                                   [-1, 3]                   --
|    └─PatchTransformerEncoder: 2-16          [-1, 2, 128]              --
|    |    └─Conv2d: 3-10                      [-1, 128, 16, 12]         163,968
|    |    └─TransformerEncoder: 3-11          [-1, 2, 128]              1,319,424
|    └─Conv2d: 2-17                           [-1, 128, 256, 192]       5,888
|    └─Sequential: 2-18                       [-1, 3]                   --
|    |    └─Linear: 3-12                      [-1, 256]                 33,024
|    |    └─LeakyReLU: 3-13                   [-1, 256]                 --
|    |    └─Linear: 3-14                      [-1, 256]                 65,792
|    |    └─LeakyReLU: 3-15                   [-1, 256]                 --
|    |    └─Linear: 3-16                      [-1, 3]                   771
===============================================================================================
Total params: 11,606,511
Trainable params: 11,606,511
Non-trainable params: 0
Total mult-adds (G): 19.48
===============================================================================================
Input size (MB): 0.94
Forward/backward pass size (MB): 187.37
Params size (MB): 44.28
Estimated Total Size (MB): 232.58
===============================================================================================

Train TD Model Summary:
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
└─multilayer: 0-1                        [-1, 49, 3, 256, 192]     --
==========================================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 20.25
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 20.25
==========================================================================================

Val TD Model Summary:
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
└─multilayer: 0-1                        [-1, 49, 3, 256, 192]     --
==========================================================================================
Total params: 0
Trainable params: 0
Non-trainable params: 0
Total mult-adds (M): 0.00
==========================================================================================
Input size (MB): 20.25
Forward/backward pass size (MB): 0.00
Params size (MB): 0.00
Estimated Total Size (MB): 20.25
==========================================================================================

------------------------------------------------------------------------------------
Model Layer Names:
--------------------------------------
encoder.stage0.patch_embed.proj.weight: torch.Size([64, 5, 7, 7])
encoder.stage0.patch_embed.proj.bias: torch.Size([64])
encoder.stage0.patch_embed.norm.weight: torch.Size([64])
encoder.stage0.patch_embed.norm.bias: torch.Size([64])
encoder.stage0.blocks.0.norm1.weight: torch.Size([64])
encoder.stage0.blocks.0.norm1.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.conv_proj_q.conv.weight: torch.Size([64, 1, 3, 3])
encoder.stage0.blocks.0.attn.conv_proj_q.bn.weight: torch.Size([64])
encoder.stage0.blocks.0.attn.conv_proj_q.bn.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.conv_proj_k.conv.weight: torch.Size([64, 1, 3, 3])
encoder.stage0.blocks.0.attn.conv_proj_k.bn.weight: torch.Size([64])
encoder.stage0.blocks.0.attn.conv_proj_k.bn.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.conv_proj_v.conv.weight: torch.Size([64, 1, 3, 3])
encoder.stage0.blocks.0.attn.conv_proj_v.bn.weight: torch.Size([64])
encoder.stage0.blocks.0.attn.conv_proj_v.bn.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.proj_q.weight: torch.Size([64, 64])
encoder.stage0.blocks.0.attn.proj_q.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.proj_k.weight: torch.Size([64, 64])
encoder.stage0.blocks.0.attn.proj_k.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.proj_v.weight: torch.Size([64, 64])
encoder.stage0.blocks.0.attn.proj_v.bias: torch.Size([64])
encoder.stage0.blocks.0.attn.proj.weight: torch.Size([64, 64])
encoder.stage0.blocks.0.attn.proj.bias: torch.Size([64])
encoder.stage0.blocks.0.norm2.weight: torch.Size([64])
encoder.stage0.blocks.0.norm2.bias: torch.Size([64])
encoder.stage0.blocks.0.mlp.fc1.weight: torch.Size([256, 64])
encoder.stage0.blocks.0.mlp.fc1.bias: torch.Size([256])
encoder.stage0.blocks.0.mlp.fc2.weight: torch.Size([64, 256])
encoder.stage0.blocks.0.mlp.fc2.bias: torch.Size([64])
encoder.stage1.patch_embed.proj.weight: torch.Size([192, 64, 3, 3])
encoder.stage1.patch_embed.proj.bias: torch.Size([192])
encoder.stage1.patch_embed.norm.weight: torch.Size([192])
encoder.stage1.patch_embed.norm.bias: torch.Size([192])
encoder.stage1.blocks.0.norm1.weight: torch.Size([192])
encoder.stage1.blocks.0.norm1.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.conv_proj_q.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.0.attn.conv_proj_q.bn.weight: torch.Size([192])
encoder.stage1.blocks.0.attn.conv_proj_q.bn.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.conv_proj_k.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.0.attn.conv_proj_k.bn.weight: torch.Size([192])
encoder.stage1.blocks.0.attn.conv_proj_k.bn.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.conv_proj_v.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.0.attn.conv_proj_v.bn.weight: torch.Size([192])
encoder.stage1.blocks.0.attn.conv_proj_v.bn.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.proj_q.weight: torch.Size([192, 192])
encoder.stage1.blocks.0.attn.proj_q.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.proj_k.weight: torch.Size([192, 192])
encoder.stage1.blocks.0.attn.proj_k.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.proj_v.weight: torch.Size([192, 192])
encoder.stage1.blocks.0.attn.proj_v.bias: torch.Size([192])
encoder.stage1.blocks.0.attn.proj.weight: torch.Size([192, 192])
encoder.stage1.blocks.0.attn.proj.bias: torch.Size([192])
encoder.stage1.blocks.0.norm2.weight: torch.Size([192])
encoder.stage1.blocks.0.norm2.bias: torch.Size([192])
encoder.stage1.blocks.0.mlp.fc1.weight: torch.Size([768, 192])
encoder.stage1.blocks.0.mlp.fc1.bias: torch.Size([768])
encoder.stage1.blocks.0.mlp.fc2.weight: torch.Size([192, 768])
encoder.stage1.blocks.0.mlp.fc2.bias: torch.Size([192])
encoder.stage1.blocks.1.norm1.weight: torch.Size([192])
encoder.stage1.blocks.1.norm1.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.conv_proj_q.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.1.attn.conv_proj_q.bn.weight: torch.Size([192])
encoder.stage1.blocks.1.attn.conv_proj_q.bn.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.conv_proj_k.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.1.attn.conv_proj_k.bn.weight: torch.Size([192])
encoder.stage1.blocks.1.attn.conv_proj_k.bn.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.conv_proj_v.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.1.attn.conv_proj_v.bn.weight: torch.Size([192])
encoder.stage1.blocks.1.attn.conv_proj_v.bn.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.proj_q.weight: torch.Size([192, 192])
encoder.stage1.blocks.1.attn.proj_q.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.proj_k.weight: torch.Size([192, 192])
encoder.stage1.blocks.1.attn.proj_k.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.proj_v.weight: torch.Size([192, 192])
encoder.stage1.blocks.1.attn.proj_v.bias: torch.Size([192])
encoder.stage1.blocks.1.attn.proj.weight: torch.Size([192, 192])
encoder.stage1.blocks.1.attn.proj.bias: torch.Size([192])
encoder.stage1.blocks.1.norm2.weight: torch.Size([192])
encoder.stage1.blocks.1.norm2.bias: torch.Size([192])
encoder.stage1.blocks.1.mlp.fc1.weight: torch.Size([768, 192])
encoder.stage1.blocks.1.mlp.fc1.bias: torch.Size([768])
encoder.stage1.blocks.1.mlp.fc2.weight: torch.Size([192, 768])
encoder.stage1.blocks.1.mlp.fc2.bias: torch.Size([192])
encoder.stage1.blocks.2.norm1.weight: torch.Size([192])
encoder.stage1.blocks.2.norm1.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.conv_proj_q.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.2.attn.conv_proj_q.bn.weight: torch.Size([192])
encoder.stage1.blocks.2.attn.conv_proj_q.bn.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.conv_proj_k.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.2.attn.conv_proj_k.bn.weight: torch.Size([192])
encoder.stage1.blocks.2.attn.conv_proj_k.bn.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.conv_proj_v.conv.weight: torch.Size([192, 1, 3, 3])
encoder.stage1.blocks.2.attn.conv_proj_v.bn.weight: torch.Size([192])
encoder.stage1.blocks.2.attn.conv_proj_v.bn.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.proj_q.weight: torch.Size([192, 192])
encoder.stage1.blocks.2.attn.proj_q.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.proj_k.weight: torch.Size([192, 192])
encoder.stage1.blocks.2.attn.proj_k.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.proj_v.weight: torch.Size([192, 192])
encoder.stage1.blocks.2.attn.proj_v.bias: torch.Size([192])
encoder.stage1.blocks.2.attn.proj.weight: torch.Size([192, 192])
encoder.stage1.blocks.2.attn.proj.bias: torch.Size([192])
encoder.stage1.blocks.2.norm2.weight: torch.Size([192])
encoder.stage1.blocks.2.norm2.bias: torch.Size([192])
encoder.stage1.blocks.2.mlp.fc1.weight: torch.Size([768, 192])
encoder.stage1.blocks.2.mlp.fc1.bias: torch.Size([768])
encoder.stage1.blocks.2.mlp.fc2.weight: torch.Size([192, 768])
encoder.stage1.blocks.2.mlp.fc2.bias: torch.Size([192])
encoder.stage2.patch_embed.proj.weight: torch.Size([384, 192, 3, 3])
encoder.stage2.patch_embed.proj.bias: torch.Size([384])
encoder.stage2.patch_embed.norm.weight: torch.Size([384])
encoder.stage2.patch_embed.norm.bias: torch.Size([384])
encoder.stage2.blocks.0.norm1.weight: torch.Size([384])
encoder.stage2.blocks.0.norm1.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.0.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.0.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.0.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.0.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.0.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.0.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.0.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.0.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.0.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.0.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.0.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.0.norm2.weight: torch.Size([384])
encoder.stage2.blocks.0.norm2.bias: torch.Size([384])
encoder.stage2.blocks.0.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.0.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.0.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.0.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.1.norm1.weight: torch.Size([384])
encoder.stage2.blocks.1.norm1.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.1.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.1.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.1.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.1.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.1.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.1.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.1.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.1.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.1.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.1.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.1.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.1.norm2.weight: torch.Size([384])
encoder.stage2.blocks.1.norm2.bias: torch.Size([384])
encoder.stage2.blocks.1.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.1.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.1.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.1.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.2.norm1.weight: torch.Size([384])
encoder.stage2.blocks.2.norm1.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.2.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.2.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.2.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.2.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.2.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.2.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.2.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.2.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.2.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.2.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.2.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.2.norm2.weight: torch.Size([384])
encoder.stage2.blocks.2.norm2.bias: torch.Size([384])
encoder.stage2.blocks.2.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.2.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.2.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.2.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.3.norm1.weight: torch.Size([384])
encoder.stage2.blocks.3.norm1.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.3.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.3.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.3.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.3.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.3.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.3.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.3.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.3.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.3.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.3.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.3.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.3.norm2.weight: torch.Size([384])
encoder.stage2.blocks.3.norm2.bias: torch.Size([384])
encoder.stage2.blocks.3.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.3.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.3.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.3.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.4.norm1.weight: torch.Size([384])
encoder.stage2.blocks.4.norm1.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.4.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.4.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.4.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.4.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.4.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.4.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.4.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.4.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.4.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.4.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.4.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.4.norm2.weight: torch.Size([384])
encoder.stage2.blocks.4.norm2.bias: torch.Size([384])
encoder.stage2.blocks.4.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.4.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.4.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.4.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.5.norm1.weight: torch.Size([384])
encoder.stage2.blocks.5.norm1.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.5.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.5.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.5.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.5.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.5.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.5.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.5.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.5.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.5.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.5.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.5.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.5.norm2.weight: torch.Size([384])
encoder.stage2.blocks.5.norm2.bias: torch.Size([384])
encoder.stage2.blocks.5.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.5.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.5.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.5.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.6.norm1.weight: torch.Size([384])
encoder.stage2.blocks.6.norm1.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.6.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.6.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.6.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.6.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.6.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.6.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.6.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.6.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.6.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.6.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.6.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.6.norm2.weight: torch.Size([384])
encoder.stage2.blocks.6.norm2.bias: torch.Size([384])
encoder.stage2.blocks.6.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.6.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.6.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.6.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.7.norm1.weight: torch.Size([384])
encoder.stage2.blocks.7.norm1.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.7.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.7.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.7.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.7.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.7.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.7.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.7.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.7.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.7.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.7.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.7.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.7.norm2.weight: torch.Size([384])
encoder.stage2.blocks.7.norm2.bias: torch.Size([384])
encoder.stage2.blocks.7.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.7.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.7.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.7.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.8.norm1.weight: torch.Size([384])
encoder.stage2.blocks.8.norm1.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.8.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.8.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.8.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.8.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.8.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.8.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.8.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.8.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.8.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.8.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.8.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.8.norm2.weight: torch.Size([384])
encoder.stage2.blocks.8.norm2.bias: torch.Size([384])
encoder.stage2.blocks.8.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.8.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.8.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.8.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.9.norm1.weight: torch.Size([384])
encoder.stage2.blocks.9.norm1.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.9.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.9.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.9.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.9.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.9.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.9.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.9.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.9.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.9.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.9.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.9.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.9.norm2.weight: torch.Size([384])
encoder.stage2.blocks.9.norm2.bias: torch.Size([384])
encoder.stage2.blocks.9.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.9.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.9.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.9.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.10.norm1.weight: torch.Size([384])
encoder.stage2.blocks.10.norm1.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.10.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.10.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.10.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.10.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.10.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.10.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.10.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.10.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.10.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.10.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.10.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.10.norm2.weight: torch.Size([384])
encoder.stage2.blocks.10.norm2.bias: torch.Size([384])
encoder.stage2.blocks.10.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.10.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.10.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.10.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.11.norm1.weight: torch.Size([384])
encoder.stage2.blocks.11.norm1.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.11.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.11.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.11.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.11.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.11.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.11.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.11.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.11.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.11.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.11.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.11.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.11.norm2.weight: torch.Size([384])
encoder.stage2.blocks.11.norm2.bias: torch.Size([384])
encoder.stage2.blocks.11.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.11.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.11.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.11.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.12.norm1.weight: torch.Size([384])
encoder.stage2.blocks.12.norm1.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.12.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.12.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.12.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.12.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.12.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.12.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.12.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.12.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.12.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.12.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.12.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.12.norm2.weight: torch.Size([384])
encoder.stage2.blocks.12.norm2.bias: torch.Size([384])
encoder.stage2.blocks.12.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.12.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.12.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.12.mlp.fc2.bias: torch.Size([384])
encoder.stage2.blocks.13.norm1.weight: torch.Size([384])
encoder.stage2.blocks.13.norm1.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.conv_proj_q.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.13.attn.conv_proj_q.bn.weight: torch.Size([384])
encoder.stage2.blocks.13.attn.conv_proj_q.bn.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.conv_proj_k.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.13.attn.conv_proj_k.bn.weight: torch.Size([384])
encoder.stage2.blocks.13.attn.conv_proj_k.bn.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.conv_proj_v.conv.weight: torch.Size([384, 1, 3, 3])
encoder.stage2.blocks.13.attn.conv_proj_v.bn.weight: torch.Size([384])
encoder.stage2.blocks.13.attn.conv_proj_v.bn.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.proj_q.weight: torch.Size([384, 384])
encoder.stage2.blocks.13.attn.proj_q.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.proj_k.weight: torch.Size([384, 384])
encoder.stage2.blocks.13.attn.proj_k.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.proj_v.weight: torch.Size([384, 384])
encoder.stage2.blocks.13.attn.proj_v.bias: torch.Size([384])
encoder.stage2.blocks.13.attn.proj.weight: torch.Size([384, 384])
encoder.stage2.blocks.13.attn.proj.bias: torch.Size([384])
encoder.stage2.blocks.13.norm2.weight: torch.Size([384])
encoder.stage2.blocks.13.norm2.bias: torch.Size([384])
encoder.stage2.blocks.13.mlp.fc1.weight: torch.Size([1536, 384])
encoder.stage2.blocks.13.mlp.fc1.bias: torch.Size([1536])
encoder.stage2.blocks.13.mlp.fc2.weight: torch.Size([384, 1536])
encoder.stage2.blocks.13.mlp.fc2.bias: torch.Size([384])
encoder.expander.weight: torch.Size([1024, 384, 2, 2])
encoder.expander.bias: torch.Size([1024])
encoder.expander_norm.weight: torch.Size([1024])
encoder.expander_norm.bias: torch.Size([1024])
decoder.contractor.weight: torch.Size([384, 1024, 2, 2])
decoder.contractor.bias: torch.Size([384])
decoder.bn_contractor.weight: torch.Size([384])
decoder.bn_contractor.bias: torch.Size([384])
decoder.up2._net.0.weight: torch.Size([384, 768, 3, 3])
decoder.up2._net.0.bias: torch.Size([384])
decoder.up2._net.1.weight: torch.Size([384])
decoder.up2._net.1.bias: torch.Size([384])
decoder.up2._net.3.weight: torch.Size([384, 384, 3, 3])
decoder.up2._net.3.bias: torch.Size([384])
decoder.up2._net.4.weight: torch.Size([384])
decoder.up2._net.4.bias: torch.Size([384])
decoder.up2._net.6.weight: torch.Size([192, 384, 3, 3])
decoder.up2._net.6.bias: torch.Size([192])
decoder.up2._net.7.weight: torch.Size([192])
decoder.up2._net.7.bias: torch.Size([192])
decoder.up1._net.0.weight: torch.Size([192, 384, 3, 3])
decoder.up1._net.0.bias: torch.Size([192])
decoder.up1._net.1.weight: torch.Size([192])
decoder.up1._net.1.bias: torch.Size([192])
decoder.up1._net.3.weight: torch.Size([192, 192, 3, 3])
decoder.up1._net.3.bias: torch.Size([192])
decoder.up1._net.4.weight: torch.Size([192])
decoder.up1._net.4.bias: torch.Size([192])
decoder.up1._net.6.weight: torch.Size([64, 192, 3, 3])
decoder.up1._net.6.bias: torch.Size([64])
decoder.up1._net.7.weight: torch.Size([64])
decoder.up1._net.7.bias: torch.Size([64])
decoder.up0._net.0.weight: torch.Size([64, 128, 3, 3])
decoder.up0._net.0.bias: torch.Size([64])
decoder.up0._net.1.weight: torch.Size([64])
decoder.up0._net.1.bias: torch.Size([64])
decoder.up0._net.3.weight: torch.Size([64, 64, 3, 3])
decoder.up0._net.3.bias: torch.Size([64])
decoder.up0._net.4.weight: torch.Size([64])
decoder.up0._net.4.bias: torch.Size([64])
decoder.up0._net.6.weight: torch.Size([64, 64, 3, 3])
decoder.up0._net.6.bias: torch.Size([64])
decoder.up0._net.7.weight: torch.Size([64])
decoder.up0._net.7.bias: torch.Size([64])
decoder.conv.weight: torch.Size([108, 64, 5, 5])
decoder.conv.bias: torch.Size([108])
adaptive_bins_layer.patch_transformer.positional_encodings: torch.Size([1200, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.self_attn.in_proj_weight: torch.Size([384, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.self_attn.in_proj_bias: torch.Size([384])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.self_attn.out_proj.weight: torch.Size([128, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.self_attn.out_proj.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.linear1.weight: torch.Size([1024, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.linear1.bias: torch.Size([1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.linear2.weight: torch.Size([128, 1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.linear2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.norm1.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.norm1.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.norm2.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.0.norm2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.self_attn.in_proj_weight: torch.Size([384, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.self_attn.in_proj_bias: torch.Size([384])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.self_attn.out_proj.weight: torch.Size([128, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.self_attn.out_proj.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.linear1.weight: torch.Size([1024, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.linear1.bias: torch.Size([1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.linear2.weight: torch.Size([128, 1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.linear2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.norm1.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.norm1.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.norm2.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.1.norm2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.self_attn.in_proj_weight: torch.Size([384, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.self_attn.in_proj_bias: torch.Size([384])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.self_attn.out_proj.weight: torch.Size([128, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.self_attn.out_proj.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.linear1.weight: torch.Size([1024, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.linear1.bias: torch.Size([1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.linear2.weight: torch.Size([128, 1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.linear2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.norm1.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.norm1.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.norm2.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.2.norm2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.self_attn.in_proj_weight: torch.Size([384, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.self_attn.in_proj_bias: torch.Size([384])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.self_attn.out_proj.weight: torch.Size([128, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.self_attn.out_proj.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.linear1.weight: torch.Size([1024, 128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.linear1.bias: torch.Size([1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.linear2.weight: torch.Size([128, 1024])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.linear2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.norm1.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.norm1.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.norm2.weight: torch.Size([128])
adaptive_bins_layer.patch_transformer.transformer_encoder.layers.3.norm2.bias: torch.Size([128])
adaptive_bins_layer.patch_transformer.embedding_convPxP.weight: torch.Size([128, 5, 16, 16])
adaptive_bins_layer.patch_transformer.embedding_convPxP.bias: torch.Size([128])
adaptive_bins_layer.conv3x3.weight: torch.Size([128, 5, 3, 3])
adaptive_bins_layer.conv3x3.bias: torch.Size([128])
adaptive_bins_layer.regressor.0.weight: torch.Size([256, 128])
adaptive_bins_layer.regressor.0.bias: torch.Size([256])
adaptive_bins_layer.regressor.2.weight: torch.Size([256, 256])
adaptive_bins_layer.regressor.2.bias: torch.Size([256])
adaptive_bins_layer.regressor.4.weight: torch.Size([3, 256])
adaptive_bins_layer.regressor.4.bias: torch.Size([3])


Train TD Model Layer Names:
--------------------------------------


Val TD Model Layer Names:
--------------------------------------



Bass aur nahi hai...
